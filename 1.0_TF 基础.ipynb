{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量--数据载体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#一些常用的赋值和操作\n",
    "#最常用：float32\n",
    "tf.zeros([3, 4], tf.int32)\n",
    "\n",
    "tf.zeros_like(x)\n",
    "tf.ones([2, 3], tf.float32)\n",
    "tf.ones_like(x)\n",
    "\n",
    "#常数\n",
    "t = tf.constant([1, 2, 3, 4], tf.float32)\n",
    "tf.constant(-1, shape=[2, 3])#-1填充的[2, 3]矩阵\n",
    "\n",
    "t = tf.linspace(10., 12., 3, name='lsp') #[10, 11, 12], 3表示3个，包括12\n",
    "\n",
    "#tf.range(start, limit, delta)#同样没有最后一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.63572717 -2.22727728 -0.78743017]\n",
      " [ 1.86381507 -2.45669842 -7.04239273]]\n",
      "[[ 1.  2.]\n",
      " [ 5.  6.]\n",
      " [ 3.  4.]]\n"
     ]
    }
   ],
   "source": [
    "norm = tf.random_normal([2, 3], mean=-1, stddev=4)\n",
    "\n",
    "c = tf.constant([\n",
    "    [1., 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "], tf.float32)\n",
    "#洗牌\n",
    "shuff = tf.random_shuffle(c)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(norm))\n",
    "print(sess.run(shuff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1., 2, 3, 4], name='a', dtype=tf.float32)\n",
    "with tf.Session() as sess:\n",
    "#     print(a.set_shape([2, 2]))#会报错\n",
    "    print(a.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[静态维数与动态维数](https://blog.csdn.net/dcrmg/article/details/79766538)\n",
    "- 在图构建过程中定义的张量拥有的维度是静态维度，这个维度可以被定义为不确定的，例如定义一个tensor的维度是[None,10]，表示这个tensor的第一个维度是不确定的，可以是任意的，None 表示具体维度值要在图运行过程中确定。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consumer: <bound method Tensor.consumers of <tf.Tensor 'a:0' shape=(4,) dtype=float32>>\n",
      "op: name: \"Add\"\n",
      "op: \"Add\"\n",
      "input: \"a\"\n",
      "input: \"b\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b = tf.constant([1., 2, 3, 4], name='b', dtype=tf.float32)\n",
    "c = tf.add(a, b)\n",
    "#a的后置操作\n",
    "print('consumer:', a.consumers)\n",
    "#c的前置操作\n",
    "print('op:', c.op)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'Add']\n"
     ]
    }
   ],
   "source": [
    "#图对象的节点\n",
    "print([node.name for node in c.graph.as_graph_def().node])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 稀疏张量\n",
    "[文档](https://blog.csdn.net/coderpai/article/details/79006157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensorValue(indices=array([[0, 2],\n",
      "       [1, 3]], dtype=int64), values=array([ 2.,  3.], dtype=float32), dense_shape=array([2, 3], dtype=int64))\n",
      "Tensor(\"SparseTensor/indices:0\", shape=(2, 2), dtype=int64)\n",
      "[[0 2]\n",
      " [1 3]]\n",
      "<tensorflow.python.framework.ops.Graph object at 0x00000272613F5518>\n",
      "['a', 'b', 'Add', 'b_1', 'Add_1', 'SparseTensor/indices', 'SparseTensor/values', 'SparseTensor/dense_shape']\n"
     ]
    }
   ],
   "source": [
    "sp = tf.SparseTensor(indices=[[0, 2], [1, 3]], values=np.array([2, 3], dtype=np.float32), dense_shape=[2, 3])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sp.eval())\n",
    "    #索引\n",
    "    print(sp.indices)\n",
    "    print(sp.indices.eval())\n",
    "    #图\n",
    "    print(sp.graph)\n",
    "#     print(ind.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 稀疏到密集转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "de = tf.sparse_to_dense(sparse_indices = [[1,2],[2,1]], output_shape = [3,3], \n",
    "    sparse_values = [2,3], default_value = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](imgs/1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "de = tf.sparse_tensor_to_dense(sp, default_value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 转化为密集布尔张量\n",
    "![](imgs/3.png)\n",
    "![](imgs/4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = tf.sparse_to_indicator(sp, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于稀疏张量的更多操作参照书和文档"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 操作--模型载体"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 计算节点\n",
    "    - operation类(P47):\n",
    "    - 计算节点的属性\n",
    "    - 数据基础操作\n",
    "    - 流图中的变量\n",
    "    - add的调用过程：\n",
    "        - 初始化时global_variavle_initializer()执行的过程\n",
    "        - 变量操作\n",
    "        - read将张量转化为标量的调用栈\n",
    "- 存储节点\n",
    "    - Variable类\n",
    "    - 变量初始值\n",
    "    - 更新操作\n",
    "    - 读取操作\n",
    "        - read对应了tensorboard的identity（内部调用）\n",
    "    - 变量操作：有状态操作，用于存储变量值，需要给定shape和size\n",
    "        - 初始化方法：利用初始值or模型恢复，均为Variable类的私有方法\n",
    "    \n",
    "- 数据节点 placeholder\n",
    "- 用例笔记：\n",
    "```python\n",
    "#没有显示指定数据形状，可以使用set_shape()改变静态维数\n",
    "x = tf.sparse_placeholder(tf.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32_ref>\n",
      "x: <tf.Variable 'Variable_1:0' shape=(2, 1) dtype=float32_ref>\n",
      "y: Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Create a variable\n",
    "w = tf.Variable([\n",
    "    [0.5, 1.]\n",
    "])\n",
    "x = tf.Variable([\n",
    "    [2.],\n",
    "    [1.],\n",
    "])\n",
    "t = tf.linspace(10., 12., 4, name='lsp')\n",
    "#操作\n",
    "y = tf.matmul(w, x)\n",
    "print('w:', w)\n",
    "print('x:', x)\n",
    "#框架搭建完成，但是没有具体的值--并没有计算\n",
    "print('y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session,会话\n",
    "- 会话，提供求解的环境，发放计算任务的客户端\n",
    "- Tensor.eval()和Operation.run()的调用栈，都是Session.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 以下方式也可以得到张量的值\n",
    "- Tensor.eval(self, feed_dict, session)\n",
    "- Operation.run(self, feed_dict, session)这两个方法需要传入session，但如果使用：\n",
    "```python\n",
    "    with tf.Session() as sess:\n",
    "        print(a.eval())\n",
    "        pass\n",
    "```\n",
    "        则不需要，这种方法会自己将sess注册为默认sess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lsp_2:0\", shape=(4,), dtype=float32) [ 10.          10.66666698  11.33333302  12.        ]\n"
     ]
    }
   ],
   "source": [
    "#对变量初始化\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(t, t.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 交互会话 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(5.)\n",
    "b = tf.constant(2.)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "print(a.eval())\n",
    "c = a + b\n",
    "print(c.eval())#类似shell编程的会话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器\n",
    "- 常见优化器（P65）\n",
    "- 优化器的组成：\n",
    "    - 父类：Optimter类，包含了：\n",
    "        - compute_gradients()：计算梯度\n",
    "        - apply_gradients()：应用梯度\n",
    "        - minimize()\n",
    "    - 各个优化器各自实现：利用稠密，稀疏梯度值更新模型参数的具体实现\n",
    "        - _apply_dense()\n",
    "        - _apply_sparse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### minimize()的实现(P66)：\n",
    "#### 重要：自己定义一些优化过程\n",
    "```python\n",
    "def minimize(self,):\n",
    "    #计算梯度， 得到梯度值与模型参数列表 <梯度，参数>\n",
    "    grads_and_vars = self.compute_gradients()\n",
    "    #筛选：非零梯度值对应的模型参数列表\n",
    "    vars_with_grad = [v for v, g in grads_and_vars if g is not None]\n",
    "    #如果没有非零梯度值，则出错\n",
    "    if not vars_with_grad:\n",
    "        raise ValueError()\n",
    "    #更新，返回模型参数值\n",
    "    return self.apply_gradients()\n",
    "```\n",
    "    以上为minimize的大致结构\n",
    "    minimize的参数(P67)，主要参数：gate_gradients,计算和运用梯度的顺序问题，关乎效率问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模板代码\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "#模型\n",
    "X = tf.placeholder(...)\n",
    "Y_ = tf.placeholder(...)\n",
    "w = tf.get_variable(...)\n",
    "b = tf.get_variable(...)\n",
    "#损失\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(...))\n",
    "#优化方式\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "global_step  = tf.Variable(0, name='global_step', trainable=False)#注意这里trainable=False\n",
    "train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(max_train_steps):\n",
    "        sess.run(train_op, feed_dict={...})\n",
    "        #日志\n",
    "        if step%log_step == 0:\n",
    "            l, weigth, bias = sess.run([loss, w, b])\n",
    "            print(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其实通过minimize的实现方式我们可以自己定义优化过程\n",
    "- 计算梯度\n",
    "- 处理梯度\n",
    "- 应用梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 计算梯度 compute_gradients() 的实现，具体参考P69\n",
    "```python\n",
    "def compute_gradients(...):\n",
    "    #数据处理与判断\n",
    "    ...#(包括获取var_list)\n",
    "    #创建计算梯度的操作\n",
    "    grads= gradients.gradients(...)\n",
    "    #这种策略下，为所有计算梯度添加控制依赖边，保证任意梯度在使用前所有梯度都计算完毕\n",
    "    if gate_gradients == Optimizer.GATE_GRAPH:\n",
    "        grads = control_flow_ops.tuple(grads)\n",
    "    #梯度模型参数表\n",
    "    grads_and_vars = list(zip(grads, var_list))\n",
    "    self._assert_valid_dtype([v for g, v in grads_and_vars if g is not None])\n",
    "    return grads_and_vars\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 梯度处理：\n",
    "- tf内置的一些梯度处理方法(P70)\n",
    "- 各种优化器的主要区别是在apply_gradients()中，我们的处理在这个之前\n",
    "- 例子\n",
    "```python\n",
    "...#创建模型\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01, beta1=0.5)\n",
    "grads_and_vars = optimizer.compute_gradients(loss, ...)\n",
    "for i, (g, v)  in enumerate(grads_and_vars):\n",
    "    if g is not None:\n",
    "        #剪裁\n",
    "        grads_and_vars[i] = (tf.clip_by_norm(g, 5), v)\n",
    "train_op = optimzer.apply_gradients(grads_and_vars)\n",
    "...\n",
    "```\n",
    "    \n",
    "    这里将minimize的计算分开，可以自己优化函数，添加需要的处理，注意要参照好minimize的实现，minimize中的一些其他参数设定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 应用梯度\n",
    "```python\n",
    "def apply_gradients(self, ...):\n",
    "    grads_and_vars = tuple(grads_and_vars)\n",
    "    #省略错误检查\n",
    "    converted_grads_and_vars = []\n",
    "    for g, v in grads_and_vars:\n",
    "        \n",
    "        #省略错误检查\n",
    "        p = _get_processor(v)#注意这里的p,获取更新的‘程序’\n",
    "        converted_grads_and_vars.append((g, v, p))\n",
    "        #转化到元祖类型，支持列表推演计算\n",
    "    converted_grads_and_vars = tuple(converted_grads_and_vars)\n",
    "    var_list = [v for g, v in grads_and_vars if g is not None]\n",
    "    #省略var_list非空判断\n",
    "    with ops.control_dependencies(None):\n",
    "        self._create_slots(var_list)\n",
    "    \n",
    "    update_ops = []#更新操作汇总表\n",
    "    self._prepare()\n",
    "    for grad, var, processor in converted_grads_and_vars:\n",
    "        if grad is None:\n",
    "            continue\n",
    "        #更新操作，使用之前的p，传入self，在更新时会使用各个optimizer的 apply_...() 方法\n",
    "        update_ops.append(processor.update_ops(self, grad))\n",
    "    #if global_step is None 如果有定义全局的迭代记录，这里有别的操作\n",
    "    apply_updates = self._finish(update_ops, name)#控制依赖，确保updates_op操作执行完成\n",
    "    \n",
    "    #省略对train_op的操作\n",
    "\n",
    "    return apply_updates\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上面这部分是对修改优化过程的总结，下面为线性回归实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training:\n",
      "Step:0, loss==11.4295, W==-0.3626, b==0.0822\n",
      "Step:50, loss==0.0978, W==0.3336, b==0.2175\n",
      "Step:100, loss==0.0955, W==0.3288, b==0.2518\n",
      "Step:150, loss==0.0933, W==0.3242, b==0.2840\n",
      "Step:200, loss==0.0915, W==0.3200, b==0.3144\n",
      "Step:250, loss==0.0898, W==0.3159, b==0.3429\n",
      "Step:300, loss==0.0883, W==0.3122, b==0.3698\n",
      "Step:350, loss==0.0870, W==0.3086, b==0.3950\n",
      "Step:400, loss==0.0859, W==0.3052, b==0.4188\n",
      "Step:450, loss==0.0848, W==0.3021, b==0.4412\n",
      "Step:500, loss==0.0839, W==0.2991, b==0.4623\n",
      "Step:550, loss==0.0831, W==0.2963, b==0.4821\n",
      "Step:600, loss==0.0824, W==0.2937, b==0.5008\n",
      "Step:650, loss==0.0818, W==0.2912, b==0.5183\n",
      "Step:700, loss==0.0812, W==0.2889, b==0.5349\n",
      "Step:750, loss==0.0807, W==0.2867, b==0.5504\n",
      "Step:800, loss==0.0803, W==0.2846, b==0.5650\n",
      "Step:850, loss==0.0799, W==0.2827, b==0.5788\n",
      "Step:900, loss==0.0796, W==0.2808, b==0.5918\n",
      "Step:950, loss==0.0793, W==0.2791, b==0.6040\n",
      "Step:1000, loss==0.0790, W==0.2775, b==0.6152\n",
      "Linear Regression Model: Y==0.2775*X+0.6152\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e0da184940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding=utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 打印日志的步长\n",
    "log_step = 50\n",
    "# ================ 1.定义超参数 ================\n",
    "# 学习率\n",
    "learning_rate = 0.01\n",
    "# 最大训练步数\n",
    "max_train_steps = 1000\n",
    "# ================ 2.输入数据 ================\n",
    "# 构造训练数据\n",
    "train_X = np.array([[3.3],[4.4],[5.5],[6.71],[6.93],[4.168],[9.779],[6.182],[7.59],[2.167],[7.042],[10.791],[5.313],[7.997],[5.654],[9.27],[3.1]], dtype=np.float32)\n",
    "train_Y = np.array([[1.7],[2.76],[2.09],[3.19],[1.694],[1.573],[3.366],[2.596],[2.53],[1.221],[2.827],[3.465],[1.65],[2.904],[2.42],[2.94],[1.3]], dtype=np.float32)\n",
    "total_samples = train_X.shape[0]\n",
    "# ================ 3.构建模型 ================\n",
    "# 输入数据\n",
    "X = tf.placeholder(tf.float32, [None, 1])\n",
    "# 模型参数\n",
    "W = tf.Variable(tf.random_normal([1, 1]), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1]), name=\"bias\")\n",
    "# 推理值\n",
    "Y = tf.matmul(X, W) + b\n",
    "# ================ 4.定义损失函数 ================\n",
    "# 实际值\n",
    "Y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "# 均方差\n",
    "loss = tf.reduce_sum(tf.pow(Y-Y_, 2))/(2*total_samples)\n",
    "# ================ 5.创建优化器 ================\n",
    "# 随机梯度下降优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "# ================ 6.定义单步训练操作 ================\n",
    "# 最小化损失值\n",
    "train_op = optimizer.minimize(loss)\n",
    "# ================ 7.创建会话 ================\n",
    "with tf.Session() as sess:\n",
    "    # 初始化全局变量\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "# ================ 8.迭代训练 ================\n",
    "    print(\"Start training:\")\n",
    "    for step in range(max_train_steps):\n",
    "        sess.run(train_op, feed_dict={X: train_X, Y_: train_Y})\n",
    "        # 每隔log_step步打印一次日志\n",
    "        if step % log_step == 0:\n",
    "            c = sess.run(loss, feed_dict={X: train_X, Y_:train_Y})\n",
    "            print(\"Step:%d, loss==%.4f, W==%.4f, b==%.4f\" % \n",
    "                    (step, c, sess.run(W), sess.run(b)))\n",
    "    # 计算训练完毕的模型在训练集上的损失值，作为指标输出\n",
    "    final_loss = sess.run(loss, feed_dict={X: train_X, Y_: train_Y})\n",
    "    # 计算训练完毕的模型参数W和b\n",
    "    weight, bias = sess.run([W, b])\n",
    "    print(\"Step:%d, loss==%.4f, W==%.4f, b==%.4f\" % \n",
    "            (max_train_steps, final_loss, sess.run(W), sess.run(b)))\n",
    "    print(\"Linear Regression Model: Y==%.4f*X+%.4f\" % (weight, bias))\n",
    "# ================ 模型可视化 ================\n",
    "    # 初始化Matplotlib后端\n",
    "    %matplotlib inline\n",
    "    # 根据训练数据X和Y，添加对应的红色圆点\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Training data')\n",
    "    # 根据模型参数和训练数据，添加蓝色（缺省色）拟合直线\n",
    "    plt.plot(train_X, weight * train_X + bias, label='Fitted line')\n",
    "    # 添加图例说明\n",
    "    plt.legend()\n",
    "    # 画出上面定义的图案\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的线性回归为唐雨迪给出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性回归2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQgruIiIlpOAuIlJC/x+n43Q+8nQEygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c142b91cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_points = 1000\n",
    "vectors_set = []\n",
    "np.random.seed(1)\n",
    "x_data = np.random.randn(1, num_points)\n",
    "y_data = x_data*0.1 + 0.3 + np.random.randn(1, num_points)*0.03\n",
    "# for i in range(num_points):\n",
    "#     x1 = np.random.normal(0.0, 0.55)\n",
    "#     y1 = x1*0.1 + 0.3 + np.random.normal(0., 0.03)\n",
    "#     vectors_set.append([x1, y1])\n",
    "# x_data = [v[0] for v in vectors_set]\n",
    "# y_data = [v[1] for v in vectors_set]\n",
    "\n",
    "plt.scatter(x_data, y_data, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0: [ 0.26849747]\n",
      "b0: [ 0.]\n",
      "loss: 0.114655\n",
      "Loss: 0.031753\n",
      "Loss: 0.00933643\n",
      "Loss: 0.00324538\n",
      "Loss: 0.00158298\n",
      "Loss: 0.00112746\n",
      "Loss: 0.0010022\n",
      "Loss: 0.000967651\n",
      "Loss: 0.000958094\n",
      "Loss: 0.000955444\n",
      "Loss: 0.000954707\n",
      "Loss: 0.000954502\n",
      "Loss: 0.000954445\n",
      "Loss: 0.000954429\n",
      "Loss: 0.000954425\n",
      "Loss: 0.000954424\n",
      "Loss: 0.000954423\n",
      "Loss: 0.000954423\n",
      "Loss: 0.000954423\n",
      "Loss: 0.000954423\n",
      "Loss: 0.000954423\n",
      "WL: [ 0.10068922]\n",
      "bL: [ 0.30079246]\n"
     ]
    }
   ],
   "source": [
    "NUM_ITER = 20\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1., 1.), name='W')\n",
    "b = tf.Variable(tf.zeros([1]), name='b')\n",
    "\n",
    "y = W*x_data + b\n",
    "#损失函数和优化方法，\n",
    "loss = tf.reduce_mean(tf.square(y - y_data), name='loss')\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.25)#学习率\n",
    "\n",
    "train = optimizer.minimize(loss, name='train')\n",
    "\n",
    "initer = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    #初始化\n",
    "    sess.run(initer)\n",
    "    print('W0:', sess.run(W))\n",
    "    print('b0:', sess.run(b))\n",
    "    print('loss:', sess.run(loss))\n",
    "    #优化\n",
    "    for step in range(NUM_ITER):\n",
    "        sess.run(train)\n",
    "        print('Loss:', sess.run(loss))\n",
    "    #结果\n",
    "    print('WL:', sess.run(W))\n",
    "    print('bL:', sess.run(b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved path: .//test_1\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([\n",
    "    [0.5, 1.]\n",
    "])\n",
    "x = tf.Variable([\n",
    "    [2.],\n",
    "    [1.],\n",
    "])\n",
    "t = tf.linspace(10., 12., 4, name='lsp')\n",
    "#操作\n",
    "y = tf.matmul(w, x)\n",
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    save_path = saver.save(sess, './/test_1')\n",
    "    print('Saved path:', save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download dataset\n",
      "WARNING:tensorflow:From <ipython-input-23-a31a90ae4518>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\sx352\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\sx352\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:219: retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From c:\\users\\sx352\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From c:\\users\\sx352\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\sx352\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\sx352\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "print('Download dataset')\n",
    "mnist = input_data.read_data_sets('data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of mnist: <class 'tensorflow.contrib.learn.python.learn.datasets.base.Datasets'>\n",
      "Size of train data: 55000\n",
      "Size of test data: 10000\n"
     ]
    }
   ],
   "source": [
    "print('type of mnist:', type(mnist))\n",
    "print('Size of train data:', mnist.train.num_examples)\n",
    "print('Size of test data:', mnist.test.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainimg = mnist.train.images\n",
    "trainlabel = mnist.train.labels\n",
    "testimg = mnist.test.images\n",
    "testlabel = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71608009 -0.00266728 -0.57348279  1.23325354]\n",
      " [-2.57076883  1.80841393 -0.33048872  0.21376287]\n",
      " [ 1.2742082   0.24959993 -0.35908264  2.4381442 ]]\n"
     ]
    }
   ],
   "source": [
    "temp = np.random.randn(3, 4)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 2\n",
      "shape: [3 4]\n",
      "argmax: [2 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "print('rank:', tf.rank(temp).eval())\n",
    "print('shape:', tf.shape(temp).eval())\n",
    "print('argmax:', tf.argmax(temp, axis=0).eval())#最大值索引，axis=0-->最后一维\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.08\n",
    "TRAINING_EPOCHS = 500\n",
    "BATCH_SIZE = 100\n",
    "DISPLAY_STEP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, 784])#第一维度无穷，第二维度732\n",
    "y = tf.placeholder('float', [None, 10])\n",
    "W = tf.Variable(tf.random_normal([784, 10]), name='W')\n",
    "b = tf.Variable(tf.zeros([10]), name='b')\n",
    "\n",
    "actv = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(actv), reduction_indices=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE)\n",
    "train = optimizer.minimize(cost, name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#预测\n",
    "pred = tf.equal(tf.argmax(actv, 1), tf.argmax(y, 1))\n",
    "#评估标准\n",
    "accr = tf.reduce_mean(tf.cast(pred, 'float'))#cast:将bool转换为float类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "num_batchs = int(mnist.train.num_examples/BATCH_SIZE)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(TRAINING_EPOCHS):\n",
    "        aver_cost = 0\n",
    "        for i in range(num_batchs):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            foods = {x:batch_xs, y:batch_ys}\n",
    "            sess.run(train, feed_dict=foods)\n",
    "            aver_cost += sess.run(cost, feed_dict=foods)\n",
    "        if epoch%DISPLAY_STEP == 0:\n",
    "            foods_test = {x:mnist.test.images, y:mnist.test.labels}\n",
    "            test_acc = sess.run(accr, feed_dict=foods_test)\n",
    "            print('Epoch:{} \\t accuracy:{}'.format(epoch+1, test_acc))\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
